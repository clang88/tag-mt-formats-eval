{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMveU2BLlhfC53CwkA2kGqO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Translation Evaluation\n","In this Notebook:\n","\n","0. Setup\n","1. Translation speed\n","2. BLEU Score\n","3. COMET\n","4. Terminology Adherence Evaluation"],"metadata":{"id":"Sfq7mcoeqUSp"}},{"cell_type":"markdown","source":["## 0. Setup"],"metadata":{"id":"viTasSanqqgx"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd"],"metadata":{"id":"d4FPdIrhEXxW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Declaration and definition of variables"],"metadata":{"id":"58a7MQoOrxXG"}},{"cell_type":"code","source":["# for Terminology Adherence Evaluation\n","# path to file containing reference (human) translations\n","reference_path = \"/reference_files\"\n","# path to file containing llm generated translations\n","prediction_path = \"/prediction_files\"\n","# path to file containing the relevant terminology (csv) (each column needs to be the respective file name)\n","terminology_file = \"terminology_DE-EN.csv\"\n","\n","# for Translation Speed Evaluation\n","# path to file containing the translation times (csv)\n","times_file = \"DE-EN_translation_times.csv\"\n","\n","# for naming the files\n","model = \"gpt-4o\"\n","# target language\n","language = \"EN\"\n","\n","# for concatenating all files (necessary for BLEU and COMET evaluation)\n","# path to folder containing all files\n","source_path = \"/source_files\""],"metadata":{"id":"nqpRbFifsXpY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### General Functions"],"metadata":{"id":"T0mm6HtMIzxG"}},{"cell_type":"code","source":["# function for creating the predictions list (llm generated translations)\n","def create_predictions(prediction_file):\n","  predictions = []\n","\n","  with open(prediction_file, \"r\", encoding=\"utf-8\") as file:\n","    predictions = [line.strip() for line in file]\n","\n","  return predictions"],"metadata":{"id":"by5RQEt5uAbB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function for concatenating all files (for BLEU and COMET)\n","\n","# output file path\n","full_data = source_path.split(\"/\")[-1] + \".txt\"\n","\n","# create output file\n","with open(full_data, 'w', encoding=\"utf-8\") as outfile:\n","    for filename in sorted(os.listdir(source_path)):\n","        print(filename)\n","        if filename.endswith('.txt'):\n","            file_path = os.path.join(source_path, filename)\n","            with open(file_path, 'r', encoding=\"utf-8\") as infile:\n","              new_file = infile.read().rstrip(\"\\n\")+\"\\n\"\n","              # Remove UTF-8 BOM if it exists\n","              if new_file.startswith('\\ufeff'):\n","                  new_file = new_file[1:]\n","              outfile.write(new_file)"],"metadata":{"collapsed":true,"id":"NeKPP2hH5CpS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1. Translation Speed"],"metadata":{"id":"N7_C0dTd_w6n"}},{"cell_type":"code","source":["# @title\n","df = pd.read_csv(times_file)\n","print(\"Average translation speed per file:\")\n","print(df.mean())\n","\n","print(\"\\nAverage translation speed over all files:\")\n","print(df.mean().mean())"],"metadata":{"id":"pkVpSLJ7AEcy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. SacreBLEU\n","\n"],"metadata":{"id":"_RWYJNsS0UXV"}},{"cell_type":"code","source":["!pip install sacrebleu"],"metadata":{"id":"uvGB-WLW4msa","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compute SacreBLEU score and compare to baseline\n","!sacrebleu en_reference.txt -l de-en -i without-tag_4o.txt markdown.txt json.txt tbx_dct.txt tbx_dca.txt yaml.txt -m bleu --paired-bs"],"metadata":{"id":"PHa4dJnX4mv1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. COMET"],"metadata":{"id":"wZHXHRNMjke6"}},{"cell_type":"code","source":["!pip install unbabel-comet"],"metadata":{"collapsed":true,"id":"-N4a4448jlep"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compute COMET score\n","!comet-score -s en_sources.txt -r en_reference.txt -t without-tag_4o.txt"],"metadata":{"id":"SFcYrKLgjqvS","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compare COMET scores\n","!comet-compare -s en_sources.txt -t without-tag_4o.txt markdown.txt json.txt tbx_dct.txt tbx_dca.txt yaml.txt -r en_reference.txt"],"metadata":{"id":"ToEVNe3gk1w7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Terminology Adherence Evaluation\n","The percentage of correctly translated terminology. Here, the files for the manual inspection of the evaluation are generated."],"metadata":{"id":"IvxwNmArC3Ad"}},{"cell_type":"code","source":["df = pd.read_csv(terminology_file)\n","print(\"Terms per file:\")\n","print(df.count())"],"metadata":{"id":"v5iGHTThDMxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creating a dictionary with the terminology for each file from the terminology csv\n","terminology = {}\n","for name, data in df.items():\n","  key_name = name.split(\"_\")[0]\n","  print(key_name)\n","  value_list = []\n","  for value in data:\n","    if pd.isna(value):\n","      value_list.append([])\n","    else:\n","      value_list.append(value.split(\"|\"))\n","\n","  terminology[key_name] = value_list"],"metadata":{"id":"7BFn76L_EQGu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creating a txt file containing the terminology errors\n","def create_incorrect_file(terminology, predictions, reference_file):\n","  column_name = reference_file.split(\"_\")[0]\n","  incorrect_file = f\"{column_name}_incorrectTerminology.txt\"\n","  final_score = 0\n","  total_terms = len([terms for terms in terminology[column_name] if terms])\n","\n","  with open(incorrect_file, \"w\") as file:\n","    for idx, (terms, prediction) in enumerate(zip((terminology[column_name]), predictions)):\n","      term_count = 0\n","      missed_terms = 0\n","      sentence_score = 0\n","      missing_terms = []\n","      for term in terms:\n","        term_count += 1\n","        if term not in prediction:\n","          missed_terms += 1\n","          missing_terms.append(term)\n","      if term_count == 0:\n","        continue\n","      sentence_score = 1/term_count * (term_count - missed_terms)\n","      final_score += sentence_score\n","      if missed_terms != 0:\n","        file.write(f\"Sentence {idx+1} ({missed_terms} out of {term_count} terms missing):\\nmissing terms: {missing_terms} \\nprediction: {prediction}\\n\\n\")\n","  return final_score/total_terms, f\"{final_score}/{total_terms}\""],"metadata":{"id":"wxc1OGXlKbMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for predfile, ref_file in zip(sorted(os.listdir(prediction_path)), sorted(os.listdir(reference_path))):\n","  if predfile.split(\"_\")[-1].split(\".\")[0] == ref_file.split(\"_\")[0]:\n","    predictions = create_predictions(os.path.join(prediction_path, pred_file))\n","    score, calculation = create_incorrect_file(terminology, predictions, ref_file)\n","    with open(f\"{model}_terminology_adherence_DE-{language}.txt\", \"a\", encoding=\"utf-8\") as file:\n","      file.write(f\"{pred_file}: {calculation} = {score}\\n\")\n","    print(f\"{pred_file}: {calculation} = {score}\")"],"metadata":{"id":"wXnzIerVQx7q"},"execution_count":null,"outputs":[]}]}