{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzcLYZwl0S6p"
   },
   "source": [
    "# Model Translation Pipeline\n",
    "\n",
    "In this Notebook:\n",
    "* Selecting a model\n",
    "* Setting system and user prompt\n",
    "* Generating translation and computing time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfrGCWFj0rQo"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebTSCelv0Tcl"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from google.colab import userdata\n",
    "from time import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIJ3g-V80uWf"
   },
   "outputs": [],
   "source": [
    "token = \"\" # openwebui api token\n",
    "base_url = \"\" # openwebui api base url\n",
    "headers = {\"Authorization\" : f\"Bearer {token}\", \"Content-Type\" : \"application/json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvBzgBgq0uZX"
   },
   "outputs": [],
   "source": [
    "# function for measuring translation times\n",
    "def timer_func(func):\n",
    "  def wrap_func(*args, **kwargs):\n",
    "    start = time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end = time()\n",
    "    execution_time = end-start\n",
    "    #print(f'Function {func.__name__!r} executed in {(end-start):.4f}s')\n",
    "    return result, execution_time\n",
    "  return wrap_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cN7ABhZ1NPQ"
   },
   "source": [
    "## Getting Available Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52doL4Bj0ufH"
   },
   "outputs": [],
   "source": [
    "def get_models(base_url, headers):\n",
    "  try:\n",
    "    response = requests.get(f\"{base_url}models\", headers=headers, verify=False)\n",
    "    return response.json()\n",
    "  except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error fetching models: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HoWo3AYM0uiP"
   },
   "outputs": [],
   "source": [
    "available_models = get_models(base_url, headers)\n",
    "for model in available_models[\"data\"]:\n",
    "  print(model[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKDN1jHp1TAX"
   },
   "source": [
    "## Generating the Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1759440630125,
     "user": {
      "displayName": "Anna",
      "userId": "17302008309429072159"
     },
     "user_tz": -120
    },
    "id": "_iaRT8Zf1VF1"
   },
   "outputs": [],
   "source": [
    "model = \"gpt-4o-2024-11-20\"\n",
    "system_prompt = \"Translate the text provided by the user from and in to the language specified by the user. Only return the translation.\"\n",
    "base_user_prompt = \"Translate from German to English: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_Jyu0L71jxo"
   },
   "outputs": [],
   "source": [
    "@timer_func\n",
    "def chat_completion(base_url, model_name, user_prompt, system_prompt:str=None):\n",
    "  headers = {\"Authorization\" : f\"Bearer {token}\", \"Content-Type\" : \"application/json\"}\n",
    "  payload = {\n",
    "      \"model\" : model,\n",
    "      \"messages\": [\n",
    "          {\"role\": \"user\", \"content\": user_prompt},\n",
    "          {\"role\": \"system\", \"content\": system_prompt},\n",
    "          ],\n",
    "      \"seed\" : 42,\n",
    "      \"temperature\" : 0.2,\n",
    "      }\n",
    "\n",
    "  response = requests.post(f\"{base_url}chat/completions\", json=payload, headers=headers, verify=False)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCPsOySL1j0I"
   },
   "outputs": [],
   "source": [
    "def generate_translation(source_path, model:str=model, base_url:str=base_url, system_prompt:str=None, base_user_prompt:str=base_user_prompt):\n",
    "  predictions = []\n",
    "  source = []\n",
    "  execution_times = []\n",
    "\n",
    "  with open(source_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "      user_prompt = base_user_prompt + line.strip()\n",
    "      source.append(line.strip())\n",
    "      # generate translation\n",
    "      response, execution_time = chat_completion(base_url, model, user_prompt)\n",
    "      execution_times.append(execution_time)\n",
    "      try:\n",
    "        predictions.append(response.json()[\"choices\"][0][\"message\"][\"content\"])\n",
    "      except KeyError:\n",
    "        print(response.json())\n",
    "\n",
    "  return predictions, source, execution_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LHg96Dk141J"
   },
   "source": [
    "### Storing the translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkCVTMkK1j24"
   },
   "outputs": [],
   "source": [
    "# store translation\n",
    "def store_translation(translation_file:str, predictions:list):\n",
    "  with open(translation_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    for translation in predictions:\n",
    "      file.write(translation + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AF0X-6_u1j6J"
   },
   "outputs": [],
   "source": [
    "# store translation times\n",
    "def store_translation_times(csv_name: str, execution_times: list, column: str):\n",
    "    if os.path.isfile(csv_name):\n",
    "        df = pd.read_csv(csv_name)\n",
    "        new_column_df = pd.DataFrame({column: execution_times})\n",
    "        df = pd.concat([df, new_column_df], axis=1)\n",
    "    else:\n",
    "        df = pd.DataFrame({column: execution_times})\n",
    "    df.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr43OdV62D3R"
   },
   "source": [
    "### Generating the translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77QA1-1E2HCQ"
   },
   "outputs": [],
   "source": [
    "source_dir = \"source_files\"\n",
    "data_name = \"DE-EN\"\n",
    "times_file = f\"{model}_{data_name}_translation_times.csv\"\n",
    "\n",
    "for file_name in os.listdir(source_dir):\n",
    "  print(file_name)\n",
    "  short_file_name = file_name.split(\"_\")[0] # file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "  source_path = os.path.join(source_dir, file_name)\n",
    "  translation_file = f\"{data_name}_json_{datetime.now().strftime('%Y_%m_%d')}_{short_file_name}.txt\"\n",
    "\n",
    "  predictions, source, execution_times = generate_translation(source_path, model=model, base_url=base_url, base_user_prompt=base_user_prompt)\n",
    "  store_translation(translation_file, predictions)\n",
    "  store_translation_times(times_file, execution_times, short_file_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPGQaDq3rFUSuB9BeyEdEci",
   "collapsed_sections": [
    "mfrGCWFj0rQo"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
